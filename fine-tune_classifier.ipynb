{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning an Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will fine-tune and alread pre-trained image classifier in Keras\n",
    "\n",
    "This notebook uses the script \"fine-tune_classifier.py\" and is meant to help *visualize* the training process. See the notebook \"evaluate_classifier.ipynb\" for methods on evaluating the image classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following utilizes a **\"Locations.py\"** (not included) script that specifies the locations of various repositories on the local machine. Thus, there needs to be slight adjustments if you have downloaded this file from Github. Specifically, you must specify the following (among potentially others):\n",
    "\n",
    "\n",
    " - **test_data_dir** = *location of test data/images*\n",
    " \n",
    " - **preview_dir** = *where to store the augmented images that are previewed (optional)*\n",
    " \n",
    " - **runs_dir** = *location of saved weights*\n",
    " \n",
    " - **arch_dir** = *location of saved model architectures*\n",
    " \n",
    " - **model_location** = *specific location of the desired model within the arch_dir*\n",
    " \n",
    " - **train_bottleneck** = *where are the training bottleneck features stored?*\n",
    " \n",
    " - **validation_bottleneck** = *where are the validating bottleneck features stored?*\n",
    " \n",
    " - **plot_dir** = *location of saved plots*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import modules/dependencies\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import random\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from IPython.display import SVG\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First, we run the script \"fine-tune_classifier.py\"\n",
    "# or %run train_classifier.py ?\n",
    "exec(open(\"fine-tune_classifier.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# access locations file (if needed)\n",
    "exec(open(\"Locations.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train model\n",
    "fully_tuned_model = fine_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optiona, display summary\n",
    "fully_tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optional, save weights. Note that weights auto saved when trained\n",
    "save_weights(which_model = fully_tuned_model, filename = \"fully_tuned_VGG16_complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optional, save plot\n",
    "save_plot(which_model = fully_tuned_model, plotname = \"fully_tuned_VGG16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optional, display plot\n",
    "SVG(model_to_dot(fully_tuned_model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Display example cat (resized)\n",
    "image_cat = \"cats/cat.98 copy.jpg\"\n",
    "image_dog = \"dogs/dog.91 copy.jpg\"\n",
    "image_path_cat = os.path.join(test_data_dir, image_cat)\n",
    "image_path_dog = os.path.join(test_data_dir, image_dog)\n",
    "\n",
    "a = Image(filename = image_path_cat, width = 150, height = 150)\n",
    "b = Image(filename = image_path_dog, width = 150, height = 150)\n",
    "display(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#optional (alread ran), create example augmented images\n",
    "img = load_img(new_image_path)  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "#example datagen\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        rotation_range=25,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode = 'nearest',\n",
    "        vertical_flip = True,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "directory = preview_dir + \"/cats\"\n",
    "for batch in train_datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir=directory, save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#display augmented images (actual size)\n",
    "a = Image(filename = preview_dir + \"/cats\" + \"/cat_0_2043.jpeg\", width = 150, height = 150)\n",
    "b = Image(filename = preview_dir + \"/cats\" + \"/cat_0_2058.jpeg\", width = 150, height = 150)\n",
    "c = Image(filename = preview_dir + \"/cats\" + \"/cat_0_2215.jpeg\", width = 150, height = 150)\n",
    "d = Image(filename = preview_dir + \"/cats\" + \"/cat_0_3130.jpeg\", width = 150, height = 150)\n",
    "e = Image(filename = preview_dir + \"/cats\" + \"/cat_0_3474.jpeg\", width = 150, height = 150)\n",
    "display(a, b, c, d, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optional, load an already trained model into notebook\n",
    "def load_model(arch = model_location, which_model = \"original_model_complete\"):\n",
    "    run = os.path.join(runs_dir, which_model)\n",
    "    model = model_from_json(open(arch).read())\n",
    "    model.load_weights(run)\n",
    "    print(\"model loaded.\")\n",
    "    return model\n",
    "\n",
    "model = load_model(arch_dir + \"/fully_tuned_VGG16.json\", runs_dir + \"/fully_tuned_VGG16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use generator to rescale and predict on test data set\n",
    "rescale_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "rescale_generator = rescale_datagen.flow_from_directory(\n",
    "        directory = test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode = \"rgb\",\n",
    "        classes = ['cats', 'dogs'],\n",
    "        batch_size=1,\n",
    "        shuffle = False,\n",
    "        class_mode='categorical')\n",
    "\n",
    "a = Image(filename = image_path_cat, width = 150, height = 150)\n",
    "b = Image(filename = image_path_dog, width = 150, height = 150)\n",
    "display(a, b)\n",
    "print(model.predict_generator(rescale_generator, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load and scale images to be tested on (different way to rescale, different answer?)\n",
    "img1 = test_data_dir + \"/dogs/oscar1.jpg\"\n",
    "img2 = test_data_dir + \"/dogs/oscar2.jpg\"\n",
    "img3 = test_data_dir + \"/dogs/oscar3.jpg\"\n",
    "img4 = test_data_dir + \"/dogs/oscar4.jpg\"\n",
    "img5 = test_data_dir + \"/dogs/oscar5.jpg\"\n",
    "o1 = Image(filename = img1, width = 150, height = 150)\n",
    "o2 = Image(filename = img2, width = 150, height = 150)\n",
    "o3 = Image(filename = img3, width = 150, height = 150)\n",
    "o4 = Image(filename = img4, width = 150, height = 150)\n",
    "o5 = Image(filename = img5, width = 150, height = 150)\n",
    "\n",
    "img_names = [img1, img2, img3, img4, img5]\n",
    "\n",
    "def load_and_scale_imgs(image_names = img_names):\n",
    "    imgs = [np.transpose(scipy.misc.imresize(scipy.misc.imread(image_name),\n",
    "                            (150, 150)), (0, 1, 2)).astype('float32') for image_name in image_names]\n",
    "    return np.array(imgs) / 255\n",
    "\n",
    "#make predictions\n",
    "imgs = load_and_scale_imgs()\n",
    "predictions = model.predict(imgs)\n",
    "display(o1, o2, o3, o4, o5)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load and scale images to be tested on (different way to rescale, different answer?)\n",
    "img_names = [image_path_cat, image_path_dog]\n",
    "\n",
    "def load_and_scale_imgs(image_names = img_names):\n",
    "    imgs = [np.transpose(scipy.misc.imresize(scipy.misc.imread(image_name),\n",
    "                            (150, 150)), (0, 1, 2)).astype('float32') for image_name in image_names]\n",
    "    return np.array(imgs) / 255\n",
    "\n",
    "#make predictions\n",
    "imgs = load_and_scale_imgs()\n",
    "predictions = model.predict_classes(imgs)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict loss on bath\n",
    "predictions = model.predict_on_batch(imgs)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
