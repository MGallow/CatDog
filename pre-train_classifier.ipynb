{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will train an image classifier using a pre-trained model in Keras\n",
    "\n",
    "This notebook uses the script \"pre-train_classifier.py\" and is meant to help *visualize* the training process. See the notebook \"evaluate_classifier.ipynb\" for methods on evaluating the image classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following utilizes a **\"Locations.py\"** (not included) script that specifies the locations of various repositories on the local machine. Thus, there needs to be slight adjustments if you have downloaded this file from Github. Specifically, you must specify the following (among potentially others):\n",
    "\n",
    "\n",
    " - **test_data_dir** = *location of test data/images*\n",
    " \n",
    " - **preview_dir** = *where to store the augmented images that are previewed (optional)*\n",
    " \n",
    " - **runs_dir** = *location of saved weights*\n",
    " \n",
    " - **arch_dir** = *location of saved model architectures*\n",
    " \n",
    " - **model_location** = *specific location of the desired model within the arch_dir*\n",
    " \n",
    " - **train_bottleneck** = *where are the training bottleneck features stored?*\n",
    " \n",
    " - **validation_bottleneck** = *where are the validating bottleneck features stored?*\n",
    " \n",
    " - **plot_dir** = *location of saved plots*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import modules/dependencies\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import random\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from IPython.display import SVG\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we need to run the \"pre-train_classifier.py\" script.\n",
    "# or %run train_classifier.py ?\n",
    "exec(open(\"pre-train_classifier.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# access locations file (if needed)\n",
    "exec(open(\"Locations.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optional, construct bottleneck features (takes ~5 hours on CPU)\n",
    "bottleneck = bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, we train model (the model that is stacked on top of the fully pre-trained model)\n",
    "trained_model = train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#optional, display summary\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#optional, save weights. Note that weights are auto saved when trained\n",
    "save_weights(which_model = trained_model, filename = \"pre-trained_top_VGG16_complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Display example cat (resized)(will need to provide own images if downloading from Github)\n",
    "image_cat = \"cats/cat.98 copy.jpg\"\n",
    "image_dog = \"dogs/dog.91 copy.jpg\"\n",
    "image_path_cat = os.path.join(test_data_dir, image_cat)\n",
    "image_path_dog = os.path.join(test_data_dir, image_dog)\n",
    "\n",
    "a = Image(filename = image_path_cat, width = 150, height = 150)\n",
    "b = Image(filename = image_path_dog, width = 150, height = 150)\n",
    "display(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optional, create example augmented images\n",
    "img = load_img(new_image_path)  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "#example datagen\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        rotation_range=25,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode = 'nearest',\n",
    "        vertical_flip = True,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "directory = preview_dir + \"/cats\"\n",
    "for batch in train_datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir=directory, save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#display augmented images (actual size)(will need to provide own images if downloading from Github)\n",
    "a = Image(filename = preview_dir + \"/cats\" + \"/cat_0_2043.jpeg\", width = 150, height = 150)\n",
    "b = Image(filename = preview_dir + \"/cats\" + \"/cat_0_2058.jpeg\", width = 150, height = 150)\n",
    "c = Image(filename = preview_dir + \"/cats\" + \"/cat_0_2215.jpeg\", width = 150, height = 150)\n",
    "d = Image(filename = preview_dir + \"/cats\" + \"/cat_0_3130.jpeg\", width = 150, height = 150)\n",
    "e = Image(filename = preview_dir + \"/cats\" + \"/cat_0_3474.jpeg\", width = 150, height = 150)\n",
    "display(a, b, c, d, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
